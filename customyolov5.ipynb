{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bbernoturbiz/customyolov5?scriptVersionId=91746274\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# P7 OpenClassrooms - Develop a proof of concept\n\n<p>Pour ce projet, j'ai voulu aller plus loin en Computer Vision, et passer de la classification d'images à l'Object Detection, avec un modèle \"State-of-the-art\", à savoir YOLO v5.</p>\n<p> J'ai choisi un dataset sur la santé des plantes. C'est un sujet assez éloigné des cas usuels de détection COCO\n\nDéveloppé sur Kaggle avec Yolov5 - https://www.kaggle.com/ultralytics/yolov5\n\nDataset public (https://public.roboflow.com/object-detection/plantdoc) récupéré depuis [Roboflow](https://roboflow.com), un outil de gestion de dataset et annotation d'images, entre autres.\n- *Overview: <br><p>The PlantDoc dataset was originally published by researchers at the Indian Institute of Technology, and described in depth in their [paper](https://arxiv.org/pdf/1911.10317.pdf). One of the paper’s authors, Pratik Kayal, shared the object detection dataset available on [GitHub](https://github.com/pratikkayal/PlantDoc-Dataset).<br>PlantDoc is a dataset of 2,569 images across 13 plant species and 30 classes (diseased and healthy) for image classification and object detection. There are 8,851 labels.</p>*\n- Dataset resized to 416*416","metadata":{}},{"cell_type":"code","source":"########################################\n## False for a normal training run\n## True to use a previously saved run (stored on WeTransfer)\ndl_weights_from_previous_run = False\n\n# if True we need some previous weights. Here is a link to my so far best backup run\nwetransfer_link = \"https://wetransfer.com/downloads/1c30f1d7780c95c565a1675f17a2276220220304223406/fca5a4a4af727dd59f51b3441101567b20220304223406/3b46c7\"\n\n# else train with settings:\n\n# Freeze YOLOv5 \n# 24 = full freeze, 10 = partial freeze, None = no freeze      --- more about freeze: https://github.com/ultralytics/yolov5/issues/1314\nFREEZE = None \n\nEPOCHS = 100","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:46:42.579035Z","iopub.execute_input":"2022-03-05T03:46:42.580054Z","iopub.status.idle":"2022-03-05T03:46:42.589223Z","shell.execute_reply.started":"2022-03-05T03:46:42.580011Z","shell.execute_reply":"2022-03-05T03:46:42.588556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Setup\n\nClone repo, install dependencies and check PyTorch and GPU.","metadata":{"id":"7mGmQbAO5pQb"}},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5  # clone\n%cd yolov5\n%pip install -qr requirements.txt  # install\n\nimport torch\nfrom yolov5 import utils\ndisplay = utils.notebook_init()  # checks\n\n# pour que display fonctionne dans un bloc\nget_ipython().ast_node_interactivity = 'all'","metadata":{"id":"wbvMlHd_QwMG","outputId":"3809e5a9-dd41-4577-fe62-5531abf7cca2","execution":{"iopub.status.busy":"2022-03-05T03:46:42.592421Z","iopub.execute_input":"2022-03-05T03:46:42.593211Z","iopub.status.idle":"2022-03-05T03:46:52.209251Z","shell.execute_reply.started":"2022-03-05T03:46:42.593173Z","shell.execute_reply":"2022-03-05T03:46:52.208391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Suivi des résultats\n\nIl sont récupérés par [Weights & Biases](https://wandb.ai/site?utm_campaign=repo_yolo_notebook) (W&B)\n- [Consulter les résultats](https://wandb.ai/bber/YOLOv5/reports/P7-Object-Detection--VmlldzoxNjQ1ODY2)\n(les tout derniers résultats sont consultables via le lien donné dans l'output du training. ATTENTION, il faut parfoit corriger l'url fournie (\"< span>\" final à effacer))","metadata":{}},{"cell_type":"code","source":"# Keep W&B key secret - Set it in Kaggle Add-ons \"Secrets\"\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_key = user_secrets.get_secret(\"wandbkey\")","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:46:52.212202Z","iopub.execute_input":"2022-03-05T03:46:52.212419Z","iopub.status.idle":"2022-03-05T03:46:52.470323Z","shell.execute_reply.started":"2022-03-05T03:46:52.212391Z","shell.execute_reply":"2022-03-05T03:46:52.469501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Weights & Biases\n%pip install -q wandb\nimport wandb\n\nwandb.login(key=wandb_key)\n\n### uncomment for only local (no recording with W&B):\n#!wandb offline","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:46:52.472544Z","iopub.execute_input":"2022-03-05T03:46:52.472837Z","iopub.status.idle":"2022-03-05T03:47:02.601243Z","shell.execute_reply.started":"2022-03-05T03:46:52.472799Z","shell.execute_reply":"2022-03-05T03:47:02.600395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utility","metadata":{}},{"cell_type":"code","source":"import os\nimport re\n\n## utils funcs for \"natural order\" sort (need it to get current exp# directory created by w&b)\ndef atoi(text):\n    return int(text) if text.isdigit() else text\ndef natural_keys(text):\n    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n\n# get last run dir 'exp#' from tvd: train, val, or detect runs\ndef get_last_exp(tvd):\n    return sorted(os.listdir('runs/'+tvd), key=natural_keys)[-1]  ","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:47:02.603835Z","iopub.execute_input":"2022-03-05T03:47:02.604622Z","iopub.status.idle":"2022-03-05T03:47:02.611188Z","shell.execute_reply.started":"2022-03-05T03:47:02.604565Z","shell.execute_reply":"2022-03-05T03:47:02.610435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Dataset\n\nYolov5 nécessite un format particulier pour le dataset annoté avec bounding box: \"Yolov5 PyTorch\"\n\nRoboflow propose l'export de ce Dataset public sous ce format, parmis d'autres. Trois tailles d'images sont disponibles, on a exporté les images en 416*416","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 416\n\n# Download zipped Dataset from Roboflow, unzip and suppress zip file\n!curl -L --progress-bar \"https://public.roboflow.com/ds/MJdP1IEG7h?key=6Q4WWXcKh1\" > roboflow.zip; unzip -qn roboflow.zip; rm roboflow.zip","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:47:02.612684Z","iopub.execute_input":"2022-03-05T03:47:02.613062Z","iopub.status.idle":"2022-03-05T03:47:05.556748Z","shell.execute_reply.started":"2022-03-05T03:47:02.613022Z","shell.execute_reply":"2022-03-05T03:47:05.555903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mv dataset to expected location, rename config file, and rename test to valid (data.yaml created by Roboflow has wrong path)\n!mv data.yaml data/plantDoc.yaml\n!mv train ..\n!mv test ../valid","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:47:05.559023Z","iopub.execute_input":"2022-03-05T03:47:05.559301Z","iopub.status.idle":"2022-03-05T03:47:07.552499Z","shell.execute_reply.started":"2022-03-05T03:47:05.559265Z","shell.execute_reply":"2022-03-05T03:47:07.551412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## TODO extract it from data/plantDoc.yaml   # easier, copy/paste from output of \n## !more data/plantDoc.yaml\nlabels = ['Apple Scab Leaf', 'Apple leaf', 'Apple rust leaf', 'Bell_pepper leaf spot', 'Bell_pepper leaf', 'Blueberry leaf', 'Cherry leaf', 'Corn Gray leaf spot', 'Corn leaf blight', 'Corn rust leaf', 'Peach leaf', 'Potato leaf early blight', 'Potato leaf late blight', 'Potato leaf', 'Raspberry leaf', 'Soyabean leaf', 'Soybean leaf', 'Squash Powdery mildew leaf', 'Strawberry leaf', 'Tomato Early blight leaf', 'Tomato Septoria leaf spot', 'Tomato leaf bacterial spot', 'Tomato leaf late blight', 'Tomato leaf mosaic virus', 'Tomato leaf yellow virus', 'Tomato leaf', 'Tomato mold leaf', 'Tomato two spotted spider mites leaf', 'grape leaf black rot', 'grape leaf']","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:47:30.292906Z","iopub.execute_input":"2022-03-05T03:47:30.293313Z","iopub.status.idle":"2022-03-05T03:47:30.299011Z","shell.execute_reply.started":"2022-03-05T03:47:30.293282Z","shell.execute_reply":"2022-03-05T03:47:30.298143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Train\n\nTrain a YOLOv5s (Yolov5 \"Small\") model on the [PlantDoc](https://public.roboflow.com/object-detection/plantdoc) dataset with `--data plantDoc.yaml`, starting from pretrained `--weights yolov5s.pt`\n\n- **Pretrained [Models](https://github.com/ultralytics/yolov5/tree/master/models)** are downloaded\nautomatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases)\n- **Training Results** are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n<br><br>","metadata":{"id":"ZY2VXXXu74w5"}},{"cell_type":"code","source":"best_weights = None\nif dl_weights_from_previous_run:\n    # get weights from previous runs (I have a copy of best result weights on WeTransfer)\n    !git clone https://github.com/iamleot/transferwee  # clone\n    !python transferwee/transferwee.py download -o custom_weights.pt {wetransfer_link}\n    best_weights = 'custom_weights.pt'\nelse:\n    # Train YOLOv5s on PlantDoc\n    if FREEZE is not None:\n        !python train.py --img {IMG_SIZE} --batch 32 --epochs {EPOCHS} --data plantDoc.yaml --weights yolov5s.pt --cache --freeze {FREEZE}\n    else:\n        !python train.py --img {IMG_SIZE} --batch 32 --epochs {EPOCHS} --data plantDoc.yaml --weights yolov5s.pt --cache\n    best_weights = 'runs/train/'+get_last_exp('train')+'/weights/best.pt'","metadata":{"id":"1NcFxRcFdJ_O","outputId":"8724d13d-6711-4a12-d96a-1c655e5c3549","execution":{"iopub.status.busy":"2022-03-05T03:47:07.554451Z","iopub.execute_input":"2022-03-05T03:47:07.554792Z","iopub.status.idle":"2022-03-05T03:47:12.993932Z","shell.execute_reply.started":"2022-03-05T03:47:07.554741Z","shell.execute_reply":"2022-03-05T03:47:12.992839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train results","metadata":{}},{"cell_type":"code","source":"try:\n    exp = get_last_exp('train')\n    print(\"* Run en cours *\")\n    print(exp)\n    print(\"* Resultats générés par train.py *\")\n    !ls runs/train/{exp}\n    display.Image(filename='runs/train/'+exp+'/results.png')\nexcept:\n    print(\"No training or result file missing\")","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:47:12.997481Z","iopub.execute_input":"2022-03-05T03:47:12.997731Z","iopub.status.idle":"2022-03-05T03:47:13.006625Z","shell.execute_reply.started":"2022-03-05T03:47:12.997702Z","shell.execute_reply":"2022-03-05T03:47:13.005892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Validation","metadata":{}},{"cell_type":"code","source":"!python val.py --weights {best_weights} --data data/plantDoc.yaml --img {IMG_SIZE} --save-conf --conf 0.4 --iou 0.50      # mAP","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:47:13.009947Z","iopub.execute_input":"2022-03-05T03:47:13.010332Z","iopub.status.idle":"2022-03-05T03:47:29.504171Z","shell.execute_reply.started":"2022-03-05T03:47:13.010302Z","shell.execute_reply":"2022-03-05T03:47:29.503303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### apercu des resultats produits \nexp = get_last_exp('val')\nprint(\"* Run en cours *\")\nprint(exp)\nprint(\"* Resultats générés par val.py *\")\n!ls runs/val/{exp}","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:47:29.505853Z","iopub.execute_input":"2022-03-05T03:47:29.506135Z","iopub.status.idle":"2022-03-05T03:47:30.211291Z","shell.execute_reply.started":"2022-03-05T03:47:29.506098Z","shell.execute_reply":"2022-03-05T03:47:30.210489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# F1 & PR curves\ntry:\n    display.Image(filename='runs/val/'+get_last_exp('val')+'/F1_curve.png', width=600)\n    display.Image(filename='runs/val/'+get_last_exp('val')+'/PR_curve.png', width=600)\nexcept:\n    print(\"Curves not found\")  #probably need a not-too-bad model to generate curves?","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:47:30.213186Z","iopub.execute_input":"2022-03-05T03:47:30.213463Z","iopub.status.idle":"2022-03-05T03:47:30.245023Z","shell.execute_reply.started":"2022-03-05T03:47:30.213428Z","shell.execute_reply":"2022-03-05T03:47:30.244419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{}},{"cell_type":"code","source":"display.Image(filename='runs/val/'+get_last_exp('val')+'/confusion_matrix.png')","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:47:30.246369Z","iopub.execute_input":"2022-03-05T03:47:30.246812Z","iopub.status.idle":"2022-03-05T03:47:30.267116Z","shell.execute_reply.started":"2022-03-05T03:47:30.246778Z","shell.execute_reply":"2022-03-05T03:47:30.266523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a batch\ndisplay.Image(filename='runs/val/'+get_last_exp('val')+'/val_batch2_pred.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:47:30.268278Z","iopub.execute_input":"2022-03-05T03:47:30.26874Z","iopub.status.idle":"2022-03-05T03:47:30.291726Z","shell.execute_reply.started":"2022-03-05T03:47:30.268703Z","shell.execute_reply":"2022-03-05T03:47:30.291117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Inference \ndetect","metadata":{}},{"cell_type":"markdown","source":"## Sample detection on one random image from validation set","metadata":{}},{"cell_type":"code","source":"# choose a rondom image from validation set, print Truth, display image\n\nfrom numpy.random import randint\n\n# recup une image au hasard parmis set validation\nval_images_path = '../valid/images'\nlen_val = len(os.listdir(val_images_path))\nrnd_idx = randint(len_val)\nprint(\"Image n°{}/{}\".format(rnd_idx, len_val))  #pour memoire au cas où elle serait remarquable\n#rnd_idx = 2  ## pas random dans ce cas, mais un exemple joli\nfile = os.listdir(val_images_path)[rnd_idx]\nfile_path = val_images_path+'/'+file\n\n# print Truth labels from val\nlabel_path = '../valid/labels/'+file[:-4]+'.txt'\nf = open(label_path, \"r\")\nlines = f.read().split('\\n')\nfor i, line in enumerate(lines):\n    print('Val Truth Object {}: {}'.format(i,labels[int(line.split()[0])]))\n\n#TODO: afficher les Truth bounding box pour pouvoir comparer visuellement avec la prédiction\n# bbox = lsplit()[1:4]\n# il faut la remettre à la bonne taille et import matplotlib (ou autre) pour l'afficher...\n\n# display original image\ndisplay.Image(filename='../valid/images/'+file)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:50:14.591276Z","iopub.execute_input":"2022-03-05T03:50:14.591573Z","iopub.status.idle":"2022-03-05T03:50:14.605744Z","shell.execute_reply.started":"2022-03-05T03:50:14.591536Z","shell.execute_reply":"2022-03-05T03:50:14.605041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detect\n### confidence --conf should(??) be max from F1 curve\n!python detect.py --weights {best_weights} --img {IMG_SIZE} --conf 0.4 --source {file_path} --save-txt --save-conf\n\n# print prediction class & confidence\nresfile_txt = 'runs/detect/'+get_last_exp('detect')+'/labels/'+file[:-4]+'.txt'\nf = open(resfile_txt, \"r\")\nlines = f.read().split('\\n')\nfor i, line in enumerate(lines):\n    lsplit = line.split()\n    if len(lsplit)>5:\n        print('Object {} - {} - Confidence: {}'.format(i,labels[int(lsplit[0])], lsplit[5]))\n\n# display\ndisplay.Image(filename='runs/detect/'+get_last_exp('detect')+'/'+file)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:50:26.685682Z","iopub.execute_input":"2022-03-05T03:50:26.686146Z","iopub.status.idle":"2022-03-05T03:50:33.894084Z","shell.execute_reply.started":"2022-03-05T03:50:26.686108Z","shell.execute_reply":"2022-03-05T03:50:33.891826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## at the beginning, we change dir to yolov5. So if we run again the whole notebook without reset, we end with some imbricated mess... Please avoid !\n!cd ..","metadata":{"execution":{"iopub.status.busy":"2022-03-05T03:50:33.896226Z","iopub.execute_input":"2022-03-05T03:50:33.896496Z","iopub.status.idle":"2022-03-05T03:50:34.555998Z","shell.execute_reply.started":"2022-03-05T03:50:33.896461Z","shell.execute_reply":"2022-03-05T03:50:34.55503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. References","metadata":{}},{"cell_type":"markdown","source":"## Yolo v5","metadata":{}},{"cell_type":"markdown","source":"<a align=\"left\" href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n<img width=\"1024\", src=\"https://user-images.githubusercontent.com/26833433/125273437-35b3fc00-e30d-11eb-9079-46f313325424.png\"></a>\n\nThis is a <em>fork</em> from the **official YOLOv5 🚀 notebook** by **Ultralytics**, freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \nFor more information please visit https://github.com/ultralytics/yolov5 and https://ultralytics.com. Thank you!","metadata":{"id":"t6MPjfT5NrKQ"}},{"cell_type":"markdown","source":"## PlantDoc Dataset","metadata":{}},{"cell_type":"markdown","source":"The PlantDoc dataset was originally published by researchers at the Indian Institute of Technology, and described in depth in their paper. One of the paper’s authors, Pratik Kayal, shared the object detection dataset available on GitHub.\n\n<img src=\"https://i.imgur.com/fGlQ0kG.png\" width=\"300\" height=\"200\">\n\n- Roboflow dataset: https://public.roboflow.com/object-detection/plantdoc\n- Original dataset GitHub: https://github.com/pratikkayal/PlantDoc-Dataset\n- arvix: https://arxiv.org/pdf/1911.10317.pdf","metadata":{}},{"cell_type":"markdown","source":"## Utility\n\nScript to download from a WeTransfer link: https://github.com/iamleot/transferwee\n\nRoboflow: https://roboflow.com\n\nWeights & Biases: https://wandb.ai/site","metadata":{}}]}